
(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-23 00:03:35.550924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-23 00:03:44.887401: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
BASE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend
EXPERIMENTS_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\experiments
IMAGE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images
LABEL_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels
Found 10 image files and 10 label files.
PLOT_SAVE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots
No existing model found at D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras, creating a new one.
Creating ResNet50V2 model...
2024-09-23 00:08:50.122002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model compiled with input shape (256, 256, 3) and 7 classes.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_0.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_0.npy (batch 1)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Spliting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 1...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7485 - loss: 0.5615
Epoch 1: val_accuracy improved from -inf to 0.89667, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m306s←[0m 1s/step - accuracy: 0.7489 - loss: 0.5608 - val_accuracy: 0.8967 - val_loss: 0.2751
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9245 - loss: 0.2372
Epoch 2: val_accuracy improved from 0.89667 to 0.95667, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9245 - loss: 0.2371 - val_accuracy: 0.9567 - val_loss: 0.1908
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9551 - loss: 0.1741
Epoch 3: val_accuracy improved from 0.95667 to 0.95944, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9551 - loss: 0.1741 - val_accuracy: 0.9594 - val_loss: 0.1519
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9674 - loss: 0.1401
Epoch 4: val_accuracy improved from 0.95944 to 0.96722, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m303s←[0m 1s/step - accuracy: 0.9674 - loss: 0.1401 - val_accuracy: 0.9672 - val_loss: 0.1288
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9753 - loss: 0.1106
Epoch 5: val_accuracy improved from 0.96722 to 0.97833, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9752 - loss: 0.1106 - val_accuracy: 0.9783 - val_loss: 0.1092
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9837 - loss: 0.0948
Epoch 6: val_accuracy improved from 0.97833 to 0.97889, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9837 - loss: 0.0948 - val_accuracy: 0.9789 - val_loss: 0.0974
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9801 - loss: 0.0883
Epoch 7: val_accuracy improved from 0.97889 to 0.98333, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9802 - loss: 0.0883 - val_accuracy: 0.9833 - val_loss: 0.0896
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9857 - loss: 0.0756
Epoch 8: val_accuracy did not improve from 0.98333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9857 - loss: 0.0756 - val_accuracy: 0.9817 - val_loss: 0.0870
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9880 - loss: 0.0676
Epoch 9: val_accuracy improved from 0.98333 to 0.98500, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9880 - loss: 0.0676 - val_accuracy: 0.9850 - val_loss: 0.0722
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9870 - loss: 0.0629
Epoch 10: val_accuracy improved from 0.98500 to 0.98611, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9870 - loss: 0.0629 - val_accuracy: 0.9861 - val_loss: 0.0654
Epoch 11/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9906 - loss: 0.0538
Epoch 11: val_accuracy improved from 0.98611 to 0.98722, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9906 - loss: 0.0538 - val_accuracy: 0.9872 - val_loss: 0.0632
Epoch 12/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9926 - loss: 0.0501
Epoch 12: val_accuracy improved from 0.98722 to 0.98944, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9926 - loss: 0.0501 - val_accuracy: 0.9894 - val_loss: 0.0582
Epoch 13/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9942 - loss: 0.0432
Epoch 13: val_accuracy did not improve from 0.98944
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9942 - loss: 0.0432 - val_accuracy: 0.9878 - val_loss: 0.0543
Epoch 14/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9943 - loss: 0.0407
Epoch 14: val_accuracy did not improve from 0.98944
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9943 - loss: 0.0407 - val_accuracy: 0.9889 - val_loss: 0.0514
Epoch 15/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9955 - loss: 0.0366
Epoch 15: val_accuracy did not improve from 0.98944
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9955 - loss: 0.0366 - val_accuracy: 0.9894 - val_loss: 0.0503
Epoch 16/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9946 - loss: 0.0362
Epoch 16: val_accuracy did not improve from 0.98944
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9946 - loss: 0.0362 - val_accuracy: 0.9889 - val_loss: 0.0463
Epoch 17/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9961 - loss: 0.0317
Epoch 17: val_accuracy did not improve from 0.98944
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9961 - loss: 0.0317 - val_accuracy: 0.9894 - val_loss: 0.0438
Epoch 18/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9949 - loss: 0.0337
Epoch 18: val_accuracy improved from 0.98944 to 0.99056, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9949 - loss: 0.0337 - val_accuracy: 0.9906 - val_loss: 0.0446
Epoch 19/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9966 - loss: 0.0261
Epoch 19: val_accuracy did not improve from 0.99056
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9966 - loss: 0.0261 - val_accuracy: 0.9906 - val_loss: 0.0424
Epoch 20/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9955 - loss: 0.0277
Epoch 20: val_accuracy did not improve from 0.99056
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m299s←[0m 1s/step - accuracy: 0.9955 - loss: 0.0277 - val_accuracy: 0.9894 - val_loss: 0.0451
Epoch 21/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9960 - loss: 0.0274
Epoch 21: val_accuracy improved from 0.99056 to 0.99167, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9960 - loss: 0.0274 - val_accuracy: 0.9917 - val_loss: 0.0386
Epoch 22/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9971 - loss: 0.0244
Epoch 22: val_accuracy did not improve from 0.99167
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9971 - loss: 0.0244 - val_accuracy: 0.9906 - val_loss: 0.0374
Epoch 23/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0217
Epoch 23: val_accuracy did not improve from 0.99167
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0217 - val_accuracy: 0.9917 - val_loss: 0.0365
Epoch 24/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9969 - loss: 0.0200
Epoch 24: val_accuracy improved from 0.99167 to 0.99222, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9969 - loss: 0.0200 - val_accuracy: 0.9922 - val_loss: 0.0380
Epoch 25/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9969 - loss: 0.0217
Epoch 25: val_accuracy did not improve from 0.99222
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9969 - loss: 0.0217 - val_accuracy: 0.9922 - val_loss: 0.0344
Epoch 26/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9972 - loss: 0.0177
Epoch 26: val_accuracy improved from 0.99222 to 0.99278, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9972 - loss: 0.0177 - val_accuracy: 0.9928 - val_loss: 0.0368
Epoch 27/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0162
Epoch 27: val_accuracy improved from 0.99278 to 0.99333, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0162 - val_accuracy: 0.9933 - val_loss: 0.0327
Epoch 28/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0155
Epoch 28: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0155 - val_accuracy: 0.9928 - val_loss: 0.0326
Epoch 29/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0163
Epoch 29: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0163 - val_accuracy: 0.9933 - val_loss: 0.0327
Epoch 30/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9988 - loss: 0.0141
Epoch 30: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9988 - loss: 0.0141 - val_accuracy: 0.9922 - val_loss: 0.0324
Epoch 31/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0125
Epoch 31: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0125 - val_accuracy: 0.9894 - val_loss: 0.0355
Epoch 32/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0134
Epoch 32: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9990 - loss: 0.0134 - val_accuracy: 0.9917 - val_loss: 0.0302
Epoch 33/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0113
Epoch 33: val_accuracy improved from 0.99333 to 0.99389, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0113 - val_accuracy: 0.9939 - val_loss: 0.0302
Epoch 34/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9992 - loss: 0.0117
Epoch 34: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9992 - loss: 0.0117 - val_accuracy: 0.9922 - val_loss: 0.0305
Epoch 35/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0108
Epoch 35: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0108 - val_accuracy: 0.9928 - val_loss: 0.0283
Epoch 36/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0104
Epoch 36: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0104 - val_accuracy: 0.9917 - val_loss: 0.0298
Epoch 37/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0094
Epoch 37: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0094 - val_accuracy: 0.9939 - val_loss: 0.0273
Epoch 38/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0082
Epoch 38: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0082 - val_accuracy: 0.9928 - val_loss: 0.0280
Epoch 39/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9995 - loss: 0.0089
Epoch 39: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9996 - loss: 0.0089 - val_accuracy: 0.9939 - val_loss: 0.0282
Epoch 40/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9996 - loss: 0.0086
Epoch 40: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9996 - loss: 0.0086 - val_accuracy: 0.9939 - val_loss: 0.0286
Epoch 41/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0067
Epoch 41: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0067 - val_accuracy: 0.9933 - val_loss: 0.0278
Epoch 42/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0083
Epoch 42: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9994 - loss: 0.0083 - val_accuracy: 0.9939 - val_loss: 0.0279
Epoch 43/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0072
Epoch 43: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0072 - val_accuracy: 0.9939 - val_loss: 0.0271
Epoch 44/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0066
Epoch 44: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.9939 - val_loss: 0.0273
Epoch 45/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0062
Epoch 45: val_accuracy did not improve from 0.99389
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0062 - val_accuracy: 0.9939 - val_loss: 0.0314
Epoch 46/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0058
Epoch 46: val_accuracy improved from 0.99389 to 0.99444, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0058 - val_accuracy: 0.9944 - val_loss: 0.0265
Epoch 47/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0059
Epoch 47: val_accuracy did not improve from 0.99444
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0059 - val_accuracy: 0.9917 - val_loss: 0.0280
Epoch 48/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0050
Epoch 48: val_accuracy did not improve from 0.99444
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0050 - val_accuracy: 0.9928 - val_loss: 0.0258
Epoch 49/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0051
Epoch 49: val_accuracy did not improve from 0.99444
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0051 - val_accuracy: 0.9939 - val_loss: 0.0271
Epoch 50/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0048
Epoch 50: val_accuracy did not improve from 0.99444
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0048 - val_accuracy: 0.9878 - val_loss: 0.0323
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m58s←[0m 1s/step - accuracy: 0.9901 - loss: 0.0297
New validation loss: 0.0258
New validation accuracy: 0.9928
Traceback (most recent call last):
  File "D:\03PersonalFiles\Thesis\I-Comprehend\src\training\resnet50v2_pipeline.py", line 126, in <module>
    best_model.save_weights(weights_save_path)
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\utils\traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\saving\saving_api.py", line 222, in save_weights
    raise ValueError(
ValueError: The filename must end in `.weights.h5`. Received: filepath=D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_1_weights.h5

(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-23 04:27:38.064217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-23 04:27:49.546681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
BASE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend
EXPERIMENTS_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\experiments
IMAGE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images
LABEL_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels
Found 10 image files and 10 label files.
PLOT_SAVE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots
Loading model from D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras...
2024-09-23 04:28:15.356887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model compiled with input shape (256, 256, 3) and 7 classes.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_1.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_1.npy (batch 2)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 2...
Epoch 1/50
←[1m 37/225←[0m ←[32m━━━←[0m←[37m━━━━━━━━━━━━━━━━━←[0m ←[1m3:13←[0m 1s/step - accuracy: 0.6339 - loss: 1.3597Traceback (most recent call last):
  File "D:\03PersonalFiles\Thesis\I-Comprehend\src\training\resnet50v2_pipeline.py", line 108, in <module>
    history = best_model.fit(X_train, y_train,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\utils\traceback_utils.py", line 117, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\backend\tensorflow\trainer.py", line 320, in fit
    logs = self.train_function(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\util\traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 833, in __call__
    result = self._call(*args, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 878, in _call
    results = tracing_compilation.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\concrete_function.py", line 1322, in _call_flat
    return self._inference_function.call_preflattened(args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 216, in call_preflattened
    flat_outputs = self.call_flat(*args)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 251, in call_flat
    outputs = self._bound_context.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\context.py", line 1552, in call_function
    outputs = execute.execute(
              ^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
^C
(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-23 04:44:02.818944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-23 04:44:12.476795: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
BASE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend
EXPERIMENTS_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\experiments
IMAGE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images
LABEL_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels
Found 10 image files and 10 label files.
PLOT_SAVE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots
Loading model from D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras...
2024-09-23 04:44:35.680251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

Model Summary:
Model: "sequential"
┌──────────────────────────────────────┬─────────────────────────────┬─────────────────┐
│ Layer (type)                         │ Output Shape                │         Param # │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ resnet50v2 (Functional)              │ (None, 8, 8, 2048)          │      23,564,800 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ global_average_pooling2d             │ (None, 2048)                │               0 │
│ (GlobalAveragePooling2D)             │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 7)                   │          14,343 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 23,607,830 (90.06 MB)
 Trainable params: 14,343 (56.03 KB)
 Non-trainable params: 23,564,800 (89.89 MB)
 Optimizer params: 28,687 (112.06 KB)

Model Configuration:
Optimizer: adam
Learning Rate: {'module': 'keras.optimizers.schedules', 'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.001, 'decay_steps': 100000, 'decay_rate': 0.96, 'staircase': True, 'name': 'ExponentialDecay'}, 'registered_name': None}
Loss: categorical_crossentropy
Metrics: ['loss', 'compile_metrics']

Model Weights Information:
Layer: resnet50v2 - Weight shape: (7, 7, 3, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (1, 1, 64, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (3, 3, 64, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (1, 1, 64, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 64, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (3, 3, 64, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (1, 1, 64, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (3, 3, 64, 64)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (64,)
Layer: resnet50v2 - Weight shape: (1, 1, 64, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (3, 3, 128, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 128, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (3, 3, 128, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (1, 1, 128, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (3, 3, 128, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (1, 1, 128, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (3, 3, 128, 128)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (128,)
Layer: resnet50v2 - Weight shape: (1, 1, 128, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (3, 3, 256, 256)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (256,)
Layer: resnet50v2 - Weight shape: (1, 1, 256, 1024)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1024,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (3, 3, 512, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 1024, 2048)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 2048)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (1, 1, 2048, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (3, 3, 512, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 2048)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (1, 1, 2048, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (3, 3, 512, 512)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (512,)
Layer: resnet50v2 - Weight shape: (1, 1, 512, 2048)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: resnet50v2 - Weight shape: (2048,)
Layer: dense - Weight shape: (2048, 7)
Layer: dense - Weight shape: (7,)

Layer Details:
Layer: resnet50v2, Trainable: False
Layer: global_average_pooling2d, Trainable: True
Layer: dense, Trainable: True

Model compiled with input shape (256, 256, 3) and 7 classes.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_1.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_1.npy (batch 2)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 2...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6552 - loss: 1.2099
Epoch 1: val_accuracy improved from -inf to 0.75944, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m312s←[0m 1s/step - accuracy: 0.6553 - loss: 1.2090 - val_accuracy: 0.7594 - val_loss: 0.7058
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7522 - loss: 0.7132
Epoch 2: val_accuracy improved from 0.75944 to 0.80056, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.7522 - loss: 0.7129 - val_accuracy: 0.8006 - val_loss: 0.5178
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7972 - loss: 0.5257
Epoch 3: val_accuracy improved from 0.80056 to 0.81722, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.7973 - loss: 0.5256 - val_accuracy: 0.8172 - val_loss: 0.4438
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8546 - loss: 0.3887
Epoch 4: val_accuracy improved from 0.81722 to 0.87389, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.8546 - loss: 0.3887 - val_accuracy: 0.8739 - val_loss: 0.3256
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8716 - loss: 0.3170
Epoch 5: val_accuracy improved from 0.87389 to 0.89389, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.8716 - loss: 0.3170 - val_accuracy: 0.8939 - val_loss: 0.2766
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8836 - loss: 0.2862
Epoch 6: val_accuracy improved from 0.89389 to 0.90722, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.8836 - loss: 0.2861 - val_accuracy: 0.9072 - val_loss: 0.2494
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9045 - loss: 0.2343
Epoch 7: val_accuracy improved from 0.90722 to 0.92556, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9046 - loss: 0.2343 - val_accuracy: 0.9256 - val_loss: 0.2149
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9238 - loss: 0.1972
Epoch 8: val_accuracy improved from 0.92556 to 0.93278, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9238 - loss: 0.1972 - val_accuracy: 0.9328 - val_loss: 0.1931
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9374 - loss: 0.1723
Epoch 9: val_accuracy improved from 0.93278 to 0.93722, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9374 - loss: 0.1723 - val_accuracy: 0.9372 - val_loss: 0.1742
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9460 - loss: 0.1620
Epoch 10: val_accuracy improved from 0.93722 to 0.94667, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9460 - loss: 0.1620 - val_accuracy: 0.9467 - val_loss: 0.1620
Epoch 11/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9491 - loss: 0.1444
Epoch 11: val_accuracy improved from 0.94667 to 0.94778, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9491 - loss: 0.1444 - val_accuracy: 0.9478 - val_loss: 0.1479
Epoch 12/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9589 - loss: 0.1227
Epoch 12: val_accuracy improved from 0.94778 to 0.95889, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9589 - loss: 0.1227 - val_accuracy: 0.9589 - val_loss: 0.1384
Epoch 13/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9631 - loss: 0.1114
Epoch 13: val_accuracy improved from 0.95889 to 0.96111, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9631 - loss: 0.1114 - val_accuracy: 0.9611 - val_loss: 0.1263
Epoch 14/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9634 - loss: 0.1144
Epoch 14: val_accuracy improved from 0.96111 to 0.96556, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9634 - loss: 0.1144 - val_accuracy: 0.9656 - val_loss: 0.1180
Epoch 15/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9715 - loss: 0.0914
Epoch 15: val_accuracy improved from 0.96556 to 0.96778, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9715 - loss: 0.0914 - val_accuracy: 0.9678 - val_loss: 0.1107
Epoch 16/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9731 - loss: 0.0852
Epoch 16: val_accuracy improved from 0.96778 to 0.97111, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9731 - loss: 0.0852 - val_accuracy: 0.9711 - val_loss: 0.1108
Epoch 17/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9738 - loss: 0.0842
Epoch 17: val_accuracy did not improve from 0.97111
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9738 - loss: 0.0842 - val_accuracy: 0.9711 - val_loss: 0.0971
Epoch 18/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9755 - loss: 0.0762
Epoch 18: val_accuracy improved from 0.97111 to 0.97556, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9755 - loss: 0.0762 - val_accuracy: 0.9756 - val_loss: 0.0951
Epoch 19/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9784 - loss: 0.0711
Epoch 19: val_accuracy improved from 0.97556 to 0.97611, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9784 - loss: 0.0711 - val_accuracy: 0.9761 - val_loss: 0.0880
Epoch 20/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9825 - loss: 0.0613
Epoch 20: val_accuracy did not improve from 0.97611
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9825 - loss: 0.0613 - val_accuracy: 0.9756 - val_loss: 0.0846
Epoch 21/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9855 - loss: 0.0574
Epoch 21: val_accuracy improved from 0.97611 to 0.97778, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9855 - loss: 0.0574 - val_accuracy: 0.9778 - val_loss: 0.0865
Epoch 22/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9881 - loss: 0.0510
Epoch 22: val_accuracy did not improve from 0.97778
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9881 - loss: 0.0511 - val_accuracy: 0.9733 - val_loss: 0.0930
Epoch 23/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9861 - loss: 0.0529
Epoch 23: val_accuracy improved from 0.97778 to 0.97944, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9860 - loss: 0.0529 - val_accuracy: 0.9794 - val_loss: 0.0734
Epoch 24/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9883 - loss: 0.0474
Epoch 24: val_accuracy improved from 0.97944 to 0.98111, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9883 - loss: 0.0474 - val_accuracy: 0.9811 - val_loss: 0.0752
Epoch 25/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9898 - loss: 0.0454
Epoch 25: val_accuracy improved from 0.98111 to 0.98278, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9898 - loss: 0.0454 - val_accuracy: 0.9828 - val_loss: 0.0698
Epoch 26/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9907 - loss: 0.0444
Epoch 26: val_accuracy improved from 0.98278 to 0.98500, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9907 - loss: 0.0444 - val_accuracy: 0.9850 - val_loss: 0.0612
Epoch 27/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9914 - loss: 0.0409
Epoch 27: val_accuracy did not improve from 0.98500
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9914 - loss: 0.0409 - val_accuracy: 0.9839 - val_loss: 0.0615
Epoch 28/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9922 - loss: 0.0390
Epoch 28: val_accuracy did not improve from 0.98500
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9922 - loss: 0.0390 - val_accuracy: 0.9850 - val_loss: 0.0590
Epoch 29/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9933 - loss: 0.0350
Epoch 29: val_accuracy improved from 0.98500 to 0.98556, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9933 - loss: 0.0350 - val_accuracy: 0.9856 - val_loss: 0.0562
Epoch 30/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9943 - loss: 0.0335
Epoch 30: val_accuracy did not improve from 0.98556
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9943 - loss: 0.0335 - val_accuracy: 0.9844 - val_loss: 0.0584
Epoch 31/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9939 - loss: 0.0334
Epoch 31: val_accuracy did not improve from 0.98556
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9939 - loss: 0.0333 - val_accuracy: 0.9833 - val_loss: 0.0566
Epoch 32/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9943 - loss: 0.0309
Epoch 32: val_accuracy did not improve from 0.98556
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9944 - loss: 0.0309 - val_accuracy: 0.9856 - val_loss: 0.0510
Epoch 33/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9979 - loss: 0.0255
Epoch 33: val_accuracy did not improve from 0.98556
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9979 - loss: 0.0255 - val_accuracy: 0.9850 - val_loss: 0.0505
Epoch 34/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9956 - loss: 0.0278
Epoch 34: val_accuracy improved from 0.98556 to 0.98778, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9956 - loss: 0.0278 - val_accuracy: 0.9878 - val_loss: 0.0477
Epoch 35/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9978 - loss: 0.0240
Epoch 35: val_accuracy did not improve from 0.98778
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9978 - loss: 0.0241 - val_accuracy: 0.9872 - val_loss: 0.0499
Epoch 36/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9983 - loss: 0.0216
Epoch 36: val_accuracy improved from 0.98778 to 0.99000, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9983 - loss: 0.0216 - val_accuracy: 0.9900 - val_loss: 0.0450
Epoch 37/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0205
Epoch 37: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9980 - loss: 0.0205 - val_accuracy: 0.9883 - val_loss: 0.0438
Epoch 38/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9982 - loss: 0.0188
Epoch 38: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9982 - loss: 0.0188 - val_accuracy: 0.9883 - val_loss: 0.0435
Epoch 39/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9984 - loss: 0.0181
Epoch 39: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9984 - loss: 0.0181 - val_accuracy: 0.9894 - val_loss: 0.0413
Epoch 40/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9987 - loss: 0.0187
Epoch 40: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9987 - loss: 0.0187 - val_accuracy: 0.9861 - val_loss: 0.0476
Epoch 41/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9976 - loss: 0.0191
Epoch 41: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9976 - loss: 0.0191 - val_accuracy: 0.9883 - val_loss: 0.0416
Epoch 42/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0151
Epoch 42: val_accuracy did not improve from 0.99000
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0151 - val_accuracy: 0.9894 - val_loss: 0.0421
Epoch 43/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9976 - loss: 0.0170
Epoch 43: val_accuracy improved from 0.99000 to 0.99111, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9976 - loss: 0.0169 - val_accuracy: 0.9911 - val_loss: 0.0373
Epoch 44/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9995 - loss: 0.0146
Epoch 44: val_accuracy did not improve from 0.99111
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9995 - loss: 0.0146 - val_accuracy: 0.9894 - val_loss: 0.0394
Epoch 45/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9995 - loss: 0.0135
Epoch 45: val_accuracy did not improve from 0.99111
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9995 - loss: 0.0135 - val_accuracy: 0.9906 - val_loss: 0.0401
Epoch 46/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9991 - loss: 0.0133
Epoch 46: val_accuracy did not improve from 0.99111
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9991 - loss: 0.0133 - val_accuracy: 0.9906 - val_loss: 0.0384
Epoch 47/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9996 - loss: 0.0121
Epoch 47: val_accuracy improved from 0.99111 to 0.99167, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9996 - loss: 0.0121 - val_accuracy: 0.9917 - val_loss: 0.0338
Epoch 48/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0118
Epoch 48: val_accuracy improved from 0.99167 to 0.99333, saving model to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0118 - val_accuracy: 0.9933 - val_loss: 0.0340
Epoch 49/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0116
Epoch 49: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0116 - val_accuracy: 0.9917 - val_loss: 0.0358
Epoch 50/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0110
Epoch 50: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9999 - loss: 0.0110 - val_accuracy: 0.9900 - val_loss: 0.0348
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m58s←[0m 1s/step - accuracy: 0.9915 - loss: 0.0458
New validation loss: 0.0338
New validation accuracy: 0.9917
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_2_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_2_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_2_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_2.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_2.npy (batch 3)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 3...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6821 - loss: 1.4053
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m309s←[0m 1s/step - accuracy: 0.6823 - loss: 1.4034 - val_accuracy: 0.7783 - val_loss: 0.6505
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8032 - loss: 0.5599
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8033 - loss: 0.5598 - val_accuracy: 0.8267 - val_loss: 0.4920
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8394 - loss: 0.4352
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8394 - loss: 0.4350 - val_accuracy: 0.8550 - val_loss: 0.3907
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8716 - loss: 0.3498
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8717 - loss: 0.3497 - val_accuracy: 0.8706 - val_loss: 0.3410
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8875 - loss: 0.2941
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8875 - loss: 0.2940 - val_accuracy: 0.8900 - val_loss: 0.3055
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9016 - loss: 0.2755
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9016 - loss: 0.2754 - val_accuracy: 0.8967 - val_loss: 0.2713
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9115 - loss: 0.2257
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9115 - loss: 0.2257 - val_accuracy: 0.9033 - val_loss: 0.2529
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9183 - loss: 0.2179
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9183 - loss: 0.2178 - val_accuracy: 0.9128 - val_loss: 0.2260
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9234 - loss: 0.1866
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9234 - loss: 0.1866 - val_accuracy: 0.9189 - val_loss: 0.2088
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9323 - loss: 0.1785
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9323 - loss: 0.1785 - val_accuracy: 0.9206 - val_loss: 0.1990
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.7778 - loss: 0.6747
New validation loss: 0.6505
New validation accuracy: 0.7783
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_3_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_3_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_3_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_3.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_3.npy (batch 4)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 4...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6968 - loss: 1.5517
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m308s←[0m 1s/step - accuracy: 0.6969 - loss: 1.5501 - val_accuracy: 0.7478 - val_loss: 0.8968
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7928 - loss: 0.7046
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.7928 - loss: 0.7043 - val_accuracy: 0.7978 - val_loss: 0.6679
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8253 - loss: 0.5280
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m296s←[0m 1s/step - accuracy: 0.8253 - loss: 0.5279 - val_accuracy: 0.8394 - val_loss: 0.5146
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8515 - loss: 0.4101
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8516 - loss: 0.4101 - val_accuracy: 0.8583 - val_loss: 0.4377
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8605 - loss: 0.4038
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8605 - loss: 0.4036 - val_accuracy: 0.8722 - val_loss: 0.3809
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8905 - loss: 0.3150
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8905 - loss: 0.3150 - val_accuracy: 0.8844 - val_loss: 0.3402
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8984 - loss: 0.2855
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8984 - loss: 0.2855 - val_accuracy: 0.8894 - val_loss: 0.3153
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9077 - loss: 0.2514
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9077 - loss: 0.2514 - val_accuracy: 0.9050 - val_loss: 0.2812
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9084 - loss: 0.2374
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9084 - loss: 0.2373 - val_accuracy: 0.9139 - val_loss: 0.2611
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9216 - loss: 0.2030
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9216 - loss: 0.2030 - val_accuracy: 0.9206 - val_loss: 0.2435
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.7466 - loss: 0.9142
New validation loss: 0.8968
New validation accuracy: 0.7478
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_4_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_4_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_4_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_4.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_4.npy (batch 5)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 5...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6663 - loss: 1.4024
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m311s←[0m 1s/step - accuracy: 0.6666 - loss: 1.4006 - val_accuracy: 0.8022 - val_loss: 0.5986
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8117 - loss: 0.5417
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8117 - loss: 0.5415 - val_accuracy: 0.8450 - val_loss: 0.4526
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8494 - loss: 0.4205
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8495 - loss: 0.4203 - val_accuracy: 0.8639 - val_loss: 0.3331
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8861 - loss: 0.2986
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8861 - loss: 0.2986 - val_accuracy: 0.8850 - val_loss: 0.2809
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9045 - loss: 0.2569
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9045 - loss: 0.2569 - val_accuracy: 0.8994 - val_loss: 0.2445
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9121 - loss: 0.2322
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9121 - loss: 0.2321 - val_accuracy: 0.9133 - val_loss: 0.2148
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9250 - loss: 0.1927
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9250 - loss: 0.1928 - val_accuracy: 0.9178 - val_loss: 0.1974
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9399 - loss: 0.1643
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9399 - loss: 0.1643 - val_accuracy: 0.9278 - val_loss: 0.1733
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9376 - loss: 0.1569
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9376 - loss: 0.1569 - val_accuracy: 0.9317 - val_loss: 0.1697
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9471 - loss: 0.1377
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9471 - loss: 0.1377 - val_accuracy: 0.9372 - val_loss: 0.1485
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.8039 - loss: 0.5901
New validation loss: 0.5986
New validation accuracy: 0.8022
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_5_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_5_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_5_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_5.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_5.npy (batch 6)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 6...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 5s/step - accuracy: 0.7653 - loss: 1.0214
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m1116s←[0m 5s/step - accuracy: 0.7655 - loss: 1.0200 - val_accuracy: 0.8450 - val_loss: 0.4661
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8832 - loss: 0.3621
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.8832 - loss: 0.3621 - val_accuracy: 0.8728 - val_loss: 0.3408
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9060 - loss: 0.2631
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9060 - loss: 0.2630 - val_accuracy: 0.9072 - val_loss: 0.2585
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9254 - loss: 0.1995
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9254 - loss: 0.1995 - val_accuracy: 0.9183 - val_loss: 0.2219
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9347 - loss: 0.1686
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9347 - loss: 0.1686 - val_accuracy: 0.9294 - val_loss: 0.1872
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9414 - loss: 0.1494
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9414 - loss: 0.1493 - val_accuracy: 0.9372 - val_loss: 0.1665
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9554 - loss: 0.1160
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m312s←[0m 1s/step - accuracy: 0.9554 - loss: 0.1160 - val_accuracy: 0.9433 - val_loss: 0.1490
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9599 - loss: 0.0978
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m296s←[0m 1s/step - accuracy: 0.9599 - loss: 0.0978 - val_accuracy: 0.9489 - val_loss: 0.1344
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9639 - loss: 0.1000
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9639 - loss: 0.0999 - val_accuracy: 0.9550 - val_loss: 0.1251
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9720 - loss: 0.0830
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9720 - loss: 0.0830 - val_accuracy: 0.9528 - val_loss: 0.1300
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.8379 - loss: 0.4870
New validation loss: 0.4661
New validation accuracy: 0.8450
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_6_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_6_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_6_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_6.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_6.npy (batch 7)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 7...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6679 - loss: 1.6302
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m307s←[0m 1s/step - accuracy: 0.6682 - loss: 1.6273 - val_accuracy: 0.8378 - val_loss: 0.4885
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8533 - loss: 0.4422
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8533 - loss: 0.4420 - val_accuracy: 0.8744 - val_loss: 0.3501
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8880 - loss: 0.3101
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8881 - loss: 0.3101 - val_accuracy: 0.8939 - val_loss: 0.2868
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9029 - loss: 0.2579
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9029 - loss: 0.2578 - val_accuracy: 0.9133 - val_loss: 0.2270
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9151 - loss: 0.2163
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9151 - loss: 0.2163 - val_accuracy: 0.9222 - val_loss: 0.2096
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9301 - loss: 0.1765
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9301 - loss: 0.1765 - val_accuracy: 0.9306 - val_loss: 0.1952
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9389 - loss: 0.1551
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9389 - loss: 0.1551 - val_accuracy: 0.9389 - val_loss: 0.1733
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9395 - loss: 0.1503
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9396 - loss: 0.1503 - val_accuracy: 0.9467 - val_loss: 0.1440
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9558 - loss: 0.1162
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9558 - loss: 0.1163 - val_accuracy: 0.9506 - val_loss: 0.1357
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9589 - loss: 0.1111
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9589 - loss: 0.1111 - val_accuracy: 0.9539 - val_loss: 0.1218
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m60s←[0m 1s/step - accuracy: 0.8426 - loss: 0.4573
New validation loss: 0.4885
New validation accuracy: 0.8378
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_7_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_7_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_7_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_7.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_7.npy (batch 8)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 8...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7228 - loss: 1.0642
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m316s←[0m 1s/step - accuracy: 0.7230 - loss: 1.0627 - val_accuracy: 0.8250 - val_loss: 0.5119
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8466 - loss: 0.4159
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8466 - loss: 0.4159 - val_accuracy: 0.8711 - val_loss: 0.3782
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8785 - loss: 0.3075
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8786 - loss: 0.3075 - val_accuracy: 0.8917 - val_loss: 0.3204
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8961 - loss: 0.2579
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8961 - loss: 0.2579 - val_accuracy: 0.9022 - val_loss: 0.2782
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9150 - loss: 0.2050
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9150 - loss: 0.2050 - val_accuracy: 0.9217 - val_loss: 0.2386
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9272 - loss: 0.1823
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9272 - loss: 0.1822 - val_accuracy: 0.9283 - val_loss: 0.2116
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9417 - loss: 0.1555
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9417 - loss: 0.1554 - val_accuracy: 0.9317 - val_loss: 0.1994
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9516 - loss: 0.1378
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9516 - loss: 0.1378 - val_accuracy: 0.9383 - val_loss: 0.1742
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9574 - loss: 0.1137
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9574 - loss: 0.1138 - val_accuracy: 0.9394 - val_loss: 0.1608
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9613 - loss: 0.1087
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9613 - loss: 0.1087 - val_accuracy: 0.9444 - val_loss: 0.1557
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.8314 - loss: 0.5117
New validation loss: 0.5119
New validation accuracy: 0.8250
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_8_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_8_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_8_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_8.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_8.npy (batch 9)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 9...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6620 - loss: 1.2302
Epoch 1: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m316s←[0m 1s/step - accuracy: 0.6623 - loss: 1.2289 - val_accuracy: 0.7700 - val_loss: 0.6709
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.7839 - loss: 0.5927
Epoch 2: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.7839 - loss: 0.5925 - val_accuracy: 0.8128 - val_loss: 0.4996
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8315 - loss: 0.4163
Epoch 3: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8315 - loss: 0.4163 - val_accuracy: 0.8439 - val_loss: 0.4071
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8556 - loss: 0.3585
Epoch 4: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8556 - loss: 0.3584 - val_accuracy: 0.8550 - val_loss: 0.3472
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8741 - loss: 0.2924
Epoch 5: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8741 - loss: 0.2924 - val_accuracy: 0.8850 - val_loss: 0.3025
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9012 - loss: 0.2505
Epoch 6: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9012 - loss: 0.2505 - val_accuracy: 0.8928 - val_loss: 0.2701
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9040 - loss: 0.2379
Epoch 7: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9040 - loss: 0.2378 - val_accuracy: 0.8978 - val_loss: 0.2605
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9155 - loss: 0.2045
Epoch 8: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9155 - loss: 0.2045 - val_accuracy: 0.9139 - val_loss: 0.2267
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9300 - loss: 0.1756
Epoch 9: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9300 - loss: 0.1756 - val_accuracy: 0.9167 - val_loss: 0.2257
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9360 - loss: 0.1575
Epoch 10: val_accuracy did not improve from 0.99333
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9360 - loss: 0.1575 - val_accuracy: 0.9128 - val_loss: 0.2186
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.7665 - loss: 0.6536
New validation loss: 0.6709
New validation accuracy: 0.7700
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_9_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_9_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_9_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_9.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_9.npy (batch 10)...
Loaded image data with shape (5225, 256, 256, 3), and label data with shape (5225, 7).
Splitting training data and validation data
Split data into 4180 training and 1045 validation samples.
Training the model with batch 10...
Epoch 1/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.6769 - loss: 1.7238
Epoch 1: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m179s←[0m 1s/step - accuracy: 0.6775 - loss: 1.7184 - val_accuracy: 0.8392 - val_loss: 0.4628
Epoch 2/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8782 - loss: 0.3495
Epoch 2: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.8782 - loss: 0.3494 - val_accuracy: 0.8919 - val_loss: 0.2943
Epoch 3/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.8974 - loss: 0.2516
Epoch 3: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.8975 - loss: 0.2514 - val_accuracy: 0.9263 - val_loss: 0.2263
Epoch 4/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9410 - loss: 0.1702
Epoch 4: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9410 - loss: 0.1702 - val_accuracy: 0.9330 - val_loss: 0.1948
Epoch 5/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9508 - loss: 0.1439
Epoch 5: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9508 - loss: 0.1439 - val_accuracy: 0.9416 - val_loss: 0.1666
Epoch 6/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9535 - loss: 0.1244
Epoch 6: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9535 - loss: 0.1243 - val_accuracy: 0.9445 - val_loss: 0.1501
Epoch 7/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9606 - loss: 0.1063
Epoch 7: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9606 - loss: 0.1062 - val_accuracy: 0.9502 - val_loss: 0.1376
Epoch 8/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9621 - loss: 0.0982
Epoch 8: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9621 - loss: 0.0981 - val_accuracy: 0.9579 - val_loss: 0.1222
Epoch 9/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9739 - loss: 0.0792
Epoch 9: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9739 - loss: 0.0791 - val_accuracy: 0.9560 - val_loss: 0.1157
Epoch 10/50
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 1s/step - accuracy: 0.9747 - loss: 0.0683
Epoch 10: val_accuracy did not improve from 0.99333
←[1m131/131←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m173s←[0m 1s/step - accuracy: 0.9747 - loss: 0.0683 - val_accuracy: 0.9598 - val_loss: 0.1058
←[1m33/33←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m35s←[0m 1s/step - accuracy: 0.8392 - loss: 0.4935
New validation loss: 0.4628
New validation accuracy: 0.8392
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_10_weights.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_10_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_10_training_history.png.
Model training complete.

(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py


(base) C:\Users\miiciii>Deacivate
'Deacivate' is not recognized as an internal or external command,
operable program or batch file.

(base) C:\Users\miiciii>Deactivate
DeprecationWarning: 'deactivate' is deprecated. Use 'conda deactivate'.

(base) C:\Users\miiciii>conda.bat deactivate

C:\Users\miiciii>Activate Thesis

C:\Users\miiciii>conda.bat activate Thesis

(Thesis) C:\Users\miiciii>D:

(Thesis) D:\>cd 03PersonalFiles/Thesis/I-Comprehend/src/training

(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-24 11:32:31.181970: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-24 11:32:43.424788: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Traceback (most recent call last):
  File "D:\03PersonalFiles\Thesis\I-Comprehend\src\training\resnet50v2_pipeline.py", line 3, in <module>
    import tensorflow as tf
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\__init__.py", line 47, in <module>
    from tensorflow._api.v2 import __internal__
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\_api\v2\__internal__\__init__.py", line 11, in <module>
    from tensorflow._api.v2.__internal__ import distribute
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\_api\v2\__internal__\distribute\__init__.py", line 8, in <module>
    from tensorflow._api.v2.__internal__.distribute import combinations
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\_api\v2\__internal__\distribute\combinations\__init__.py", line 8, in <module>
    from tensorflow.python.distribute.combinations import env # line: 456
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\distribute\combinations.py", line 35, in <module>
    from tensorflow.python.distribute import multi_process_runner
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\distribute\multi_process_runner.py", line 35, in <module>
    from tensorflow.python.distribute import multi_process_lib
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\distribute\multi_process_lib.py", line 25, in <module>
    from tensorflow.python.eager import test
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\test.py", line 18, in <module>
    from tensorflow.python.platform import test as _test
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\platform\test.py", line 23, in <module>
    from tensorflow.python.framework import test_util as _test_util
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\framework\test_util.py", line 36, in <module>
    from absl.testing import parameterized
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\absl\testing\parameterized.py", line 222, in <module>
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1087, in get_code
  File "<frozen importlib._bootstrap_external>", line 1187, in get_data
KeyboardInterrupt
^C
(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-24 11:35:33.406617: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-24 11:35:34.286688: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
BASE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend
EXPERIMENTS_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\experiments
IMAGE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images
LABEL_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels
Found 10 image files and 10 label files.
PLOT_SAVE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots
Loading model from D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras...
2024-09-24 11:36:02.436914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

Model compiled with input shape (256, 256, 3) and 7 classes.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_2.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_2.npy (batch 3)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 3...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m306s←[0m 1s/step - accuracy: 0.6098 - loss: 2.0669 - val_accuracy: 0.7011 - val_loss: 1.0185
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.7207 - loss: 0.9267 - val_accuracy: 0.7411 - val_loss: 0.7811
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.7609 - loss: 0.7067 - val_accuracy: 0.7750 - val_loss: 0.6352
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8043 - loss: 0.5626 - val_accuracy: 0.7983 - val_loss: 0.5536
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8193 - loss: 0.4842 - val_accuracy: 0.8272 - val_loss: 0.4691
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8390 - loss: 0.4237 - val_accuracy: 0.8456 - val_loss: 0.4078
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8719 - loss: 0.3329 - val_accuracy: 0.8611 - val_loss: 0.3675
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8819 - loss: 0.3162 - val_accuracy: 0.8711 - val_loss: 0.3358
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8984 - loss: 0.2809 - val_accuracy: 0.8817 - val_loss: 0.3032
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9036 - loss: 0.2604 - val_accuracy: 0.8939 - val_loss: 0.2811
Epoch 11/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9015 - loss: 0.2461 - val_accuracy: 0.9017 - val_loss: 0.2621
Epoch 12/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9197 - loss: 0.2165 - val_accuracy: 0.9083 - val_loss: 0.2463
Epoch 13/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9241 - loss: 0.1953 - val_accuracy: 0.9172 - val_loss: 0.2231
Epoch 14/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9285 - loss: 0.1886 - val_accuracy: 0.9217 - val_loss: 0.2034
Epoch 15/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9338 - loss: 0.1653 - val_accuracy: 0.9256 - val_loss: 0.1916
Epoch 16/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9391 - loss: 0.1613 - val_accuracy: 0.9289 - val_loss: 0.1819
Epoch 17/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9500 - loss: 0.1310 - val_accuracy: 0.9394 - val_loss: 0.1676
Epoch 18/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9489 - loss: 0.1358 - val_accuracy: 0.9394 - val_loss: 0.1601
Epoch 19/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9531 - loss: 0.1262 - val_accuracy: 0.9322 - val_loss: 0.1653
Epoch 20/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9553 - loss: 0.1179 - val_accuracy: 0.9428 - val_loss: 0.1495
Epoch 21/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9638 - loss: 0.1050 - val_accuracy: 0.9528 - val_loss: 0.1353
Epoch 22/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9674 - loss: 0.0964 - val_accuracy: 0.9528 - val_loss: 0.1276
Epoch 23/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9682 - loss: 0.0930 - val_accuracy: 0.9544 - val_loss: 0.1224
Epoch 24/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9733 - loss: 0.0814 - val_accuracy: 0.9544 - val_loss: 0.1254
Epoch 25/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9737 - loss: 0.0834 - val_accuracy: 0.9583 - val_loss: 0.1115
Epoch 26/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9716 - loss: 0.0818 - val_accuracy: 0.9594 - val_loss: 0.1120
Epoch 27/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9780 - loss: 0.0754 - val_accuracy: 0.9478 - val_loss: 0.1239
Epoch 28/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9727 - loss: 0.0776 - val_accuracy: 0.9617 - val_loss: 0.1034
Epoch 29/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9796 - loss: 0.0687 - val_accuracy: 0.9656 - val_loss: 0.0964
Epoch 30/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9767 - loss: 0.0709 - val_accuracy: 0.9678 - val_loss: 0.0943
Epoch 31/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9858 - loss: 0.0547 - val_accuracy: 0.9661 - val_loss: 0.0956
Epoch 32/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9805 - loss: 0.0614 - val_accuracy: 0.9644 - val_loss: 0.0962
Epoch 33/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9841 - loss: 0.0568 - val_accuracy: 0.9706 - val_loss: 0.0861
Epoch 34/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9854 - loss: 0.0522 - val_accuracy: 0.9733 - val_loss: 0.0801
Epoch 35/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9862 - loss: 0.0490 - val_accuracy: 0.9722 - val_loss: 0.0798
Epoch 36/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9872 - loss: 0.0519 - val_accuracy: 0.9744 - val_loss: 0.0749
Epoch 37/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9874 - loss: 0.0468 - val_accuracy: 0.9706 - val_loss: 0.0774
Epoch 38/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9873 - loss: 0.0488 - val_accuracy: 0.9739 - val_loss: 0.0732
Epoch 39/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9901 - loss: 0.0437 - val_accuracy: 0.9756 - val_loss: 0.0710
Epoch 40/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9888 - loss: 0.0427 - val_accuracy: 0.9761 - val_loss: 0.0694
Epoch 41/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9921 - loss: 0.0398 - val_accuracy: 0.9778 - val_loss: 0.0688
Epoch 42/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9899 - loss: 0.0390 - val_accuracy: 0.9761 - val_loss: 0.0694
Epoch 43/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9927 - loss: 0.0365 - val_accuracy: 0.9778 - val_loss: 0.0659
Epoch 44/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m1215s←[0m 5s/step - accuracy: 0.9915 - loss: 0.0376 - val_accuracy: 0.9800 - val_loss: 0.0622
Epoch 45/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9940 - loss: 0.0331 - val_accuracy: 0.9800 - val_loss: 0.0600
Epoch 46/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9941 - loss: 0.0325 - val_accuracy: 0.9828 - val_loss: 0.0581
Epoch 47/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m287s←[0m 1s/step - accuracy: 0.9946 - loss: 0.0308 - val_accuracy: 0.9811 - val_loss: 0.0571
Epoch 48/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9950 - loss: 0.0311 - val_accuracy: 0.9833 - val_loss: 0.0574
Epoch 49/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9933 - loss: 0.0298 - val_accuracy: 0.9822 - val_loss: 0.0552
Epoch 50/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.9965 - loss: 0.0257 - val_accuracy: 0.9856 - val_loss: 0.0533
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m57s←[0m 1s/step - accuracy: 0.9901 - loss: 0.0514
New validation loss: 0.0533
New validation accuracy: 0.9856
Model saved to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras.
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_3.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_3_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_3_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_3.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_3.npy (batch 4)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 4...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m302s←[0m 1s/step - accuracy: 0.6943 - loss: 1.5399 - val_accuracy: 0.7800 - val_loss: 0.8038
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.8116 - loss: 0.6623 - val_accuracy: 0.8078 - val_loss: 0.5999
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.8437 - loss: 0.4708 - val_accuracy: 0.8406 - val_loss: 0.4707
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.8634 - loss: 0.3956 - val_accuracy: 0.8606 - val_loss: 0.4084
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.8800 - loss: 0.3258 - val_accuracy: 0.8767 - val_loss: 0.3672
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.8946 - loss: 0.2941 - val_accuracy: 0.8856 - val_loss: 0.3361
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9050 - loss: 0.2650 - val_accuracy: 0.8844 - val_loss: 0.3318
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9080 - loss: 0.2303 - val_accuracy: 0.8972 - val_loss: 0.2941
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9218 - loss: 0.2109 - val_accuracy: 0.9122 - val_loss: 0.2659
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m292s←[0m 1s/step - accuracy: 0.9235 - loss: 0.2032 - val_accuracy: 0.9233 - val_loss: 0.2499
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m58s←[0m 1s/step - accuracy: 0.7691 - loss: 0.7968
New validation loss: 0.8038
New validation accuracy: 0.7800
Model saved to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras.
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_4.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_4_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_4_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_4.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_4.npy (batch 5)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 5...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m300s←[0m 1s/step - accuracy: 0.6648 - loss: 1.3744 - val_accuracy: 0.8161 - val_loss: 0.6367
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8078 - loss: 0.5880 - val_accuracy: 0.8461 - val_loss: 0.4720
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8478 - loss: 0.4348 - val_accuracy: 0.8667 - val_loss: 0.3766
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m288s←[0m 1s/step - accuracy: 0.8698 - loss: 0.3550 - val_accuracy: 0.8856 - val_loss: 0.3084
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.8918 - loss: 0.3000 - val_accuracy: 0.8967 - val_loss: 0.2596
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.8996 - loss: 0.2754 - val_accuracy: 0.9111 - val_loss: 0.2317
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9185 - loss: 0.2143 - val_accuracy: 0.9228 - val_loss: 0.2096
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m291s←[0m 1s/step - accuracy: 0.9276 - loss: 0.1852 - val_accuracy: 0.9272 - val_loss: 0.1894
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m289s←[0m 1s/step - accuracy: 0.9351 - loss: 0.1725 - val_accuracy: 0.9328 - val_loss: 0.1774
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m290s←[0m 1s/step - accuracy: 0.9373 - loss: 0.1553 - val_accuracy: 0.9389 - val_loss: 0.1606
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m57s←[0m 1s/step - accuracy: 0.8160 - loss: 0.6097
New validation loss: 0.6367
New validation accuracy: 0.8161
Model saved to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras.
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_5.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_5_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_5_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_5.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_5.npy (batch 6)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 6...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m309s←[0m 1s/step - accuracy: 0.7654 - loss: 1.0647 - val_accuracy: 0.8383 - val_loss: 0.5515
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.8621 - loss: 0.4477 - val_accuracy: 0.8806 - val_loss: 0.3829
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.8988 - loss: 0.3069 - val_accuracy: 0.8983 - val_loss: 0.3099
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m5243s←[0m 23s/step - accuracy: 0.9166 - loss: 0.2455 - val_accuracy: 0.9133 - val_loss: 0.2658
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9253 - loss: 0.2112 - val_accuracy: 0.9233 - val_loss: 0.2255
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m318s←[0m 1s/step - accuracy: 0.9428 - loss: 0.1533 - val_accuracy: 0.9250 - val_loss: 0.2155
Epoch 7/50
←[1m 27/225←[0m ←[32m━━←[0m←[37m━━━━━━━━━━━━━━━━━━←[0m ←[1m3:39←[0m 1s/step - accuracy: 0.9518 - loss: 0.1302Traceback (most recent call last):
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 251, in call_flat
    outputs = self._bound_context.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\context.py", line 1552, in call_function
    outputs = execute.execute(
              ^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\03PersonalFiles\Thesis\I-Comprehend\src\training\resnet50v2_pipeline.py", line 101, in <module>
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\utils\traceback_utils.py", line 117, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\keras\src\backend\tensorflow\trainer.py", line 320, in fit
    logs = self.train_function(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\util\traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 833, in __call__
    result = self._call(*args, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 878, in _call
    results = tracing_compilation.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\concrete_function.py", line 1322, in _call_flat
    return self._inference_function.call_preflattened(args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 216, in call_preflattened
    flat_outputs = self.call_flat(*args)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 249, in call_flat
    with record.stop_recording():
  File "D:\01SetupFiles\AnacondaNavigator\anacondanavigatorfiles\envs\Thesis\Lib\contextlib.py", line 141, in __exit__
    def __exit__(self, typ, value, traceback):

KeyboardInterrupt
^C
(Thesis) D:\03PersonalFiles\Thesis\I-Comprehend\src\training>python resnet50v2_pipeline.py
2024-09-24 22:22:22.854441: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-24 22:22:34.949437: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
BASE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend
EXPERIMENTS_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\experiments
IMAGE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images
LABEL_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels
Found 10 image files and 10 label files.
PLOT_SAVE_DIR: D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots
Loading model from D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras...
2024-09-24 22:23:05.111009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

Model compiled with input shape (256, 256, 3) and 7 classes.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_5.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_5.npy (batch 6)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 6...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m312s←[0m 1s/step - accuracy: 0.7320 - loss: 1.2629 - val_accuracy: 0.8311 - val_loss: 0.6790
Epoch 2/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.8352 - loss: 0.6073 - val_accuracy: 0.8606 - val_loss: 0.4925
Epoch 3/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.8783 - loss: 0.4164 - val_accuracy: 0.8778 - val_loss: 0.3945
Epoch 4/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9057 - loss: 0.2970 - val_accuracy: 0.9006 - val_loss: 0.3170
Epoch 5/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m2287s←[0m 10s/step - accuracy: 0.9114 - loss: 0.2614 - val_accuracy: 0.9106 - val_loss: 0.2690
Epoch 6/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9287 - loss: 0.2089 - val_accuracy: 0.9200 - val_loss: 0.2436
Epoch 7/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9335 - loss: 0.1705 - val_accuracy: 0.9311 - val_loss: 0.2101
Epoch 8/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9406 - loss: 0.1550 - val_accuracy: 0.9322 - val_loss: 0.1880
Epoch 9/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9518 - loss: 0.1210 - val_accuracy: 0.9439 - val_loss: 0.1672
Epoch 10/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9607 - loss: 0.1073 - val_accuracy: 0.9478 - val_loss: 0.1555
Epoch 11/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9610 - loss: 0.1008 - val_accuracy: 0.9517 - val_loss: 0.1423
Epoch 12/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9685 - loss: 0.0827 - val_accuracy: 0.9533 - val_loss: 0.1392
Epoch 13/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9709 - loss: 0.0743 - val_accuracy: 0.9561 - val_loss: 0.1285
Epoch 14/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9774 - loss: 0.0671 - val_accuracy: 0.9600 - val_loss: 0.1236
Epoch 15/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9753 - loss: 0.0712 - val_accuracy: 0.9661 - val_loss: 0.1062
Epoch 16/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9801 - loss: 0.0568 - val_accuracy: 0.9656 - val_loss: 0.1043
Epoch 17/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9837 - loss: 0.0529 - val_accuracy: 0.9667 - val_loss: 0.1002
Epoch 18/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m307s←[0m 1s/step - accuracy: 0.9840 - loss: 0.0493 - val_accuracy: 0.9700 - val_loss: 0.0937
Epoch 19/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9825 - loss: 0.0556 - val_accuracy: 0.9694 - val_loss: 0.0865
Epoch 20/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9845 - loss: 0.0419 - val_accuracy: 0.9728 - val_loss: 0.0830
Epoch 21/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9892 - loss: 0.0338 - val_accuracy: 0.9700 - val_loss: 0.0814
Epoch 22/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9905 - loss: 0.0330 - val_accuracy: 0.9728 - val_loss: 0.0751
Epoch 23/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9905 - loss: 0.0309 - val_accuracy: 0.9761 - val_loss: 0.0741
Epoch 24/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9915 - loss: 0.0274 - val_accuracy: 0.9772 - val_loss: 0.0707
Epoch 25/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m293s←[0m 1s/step - accuracy: 0.9940 - loss: 0.0246 - val_accuracy: 0.9767 - val_loss: 0.0682
Epoch 26/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9955 - loss: 0.0220 - val_accuracy: 0.9783 - val_loss: 0.0637
Epoch 27/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9947 - loss: 0.0211 - val_accuracy: 0.9800 - val_loss: 0.0668
Epoch 28/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9933 - loss: 0.0213 - val_accuracy: 0.9789 - val_loss: 0.0607
Epoch 29/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9953 - loss: 0.0181 - val_accuracy: 0.9806 - val_loss: 0.0610
Epoch 30/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9944 - loss: 0.0198 - val_accuracy: 0.9822 - val_loss: 0.0617
Epoch 31/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9956 - loss: 0.0175 - val_accuracy: 0.9811 - val_loss: 0.0547
Epoch 32/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9966 - loss: 0.0156 - val_accuracy: 0.9833 - val_loss: 0.0536
Epoch 33/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9968 - loss: 0.0142 - val_accuracy: 0.9844 - val_loss: 0.0491
Epoch 34/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9981 - loss: 0.0122 - val_accuracy: 0.9817 - val_loss: 0.0593
Epoch 35/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9988 - loss: 0.0111 - val_accuracy: 0.9833 - val_loss: 0.0509
Epoch 36/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m295s←[0m 1s/step - accuracy: 0.9976 - loss: 0.0110 - val_accuracy: 0.9844 - val_loss: 0.0481
Epoch 37/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m297s←[0m 1s/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9833 - val_loss: 0.0533
Epoch 38/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m298s←[0m 1s/step - accuracy: 0.9986 - loss: 0.0093 - val_accuracy: 0.9844 - val_loss: 0.0449
Epoch 39/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m313s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0078 - val_accuracy: 0.9850 - val_loss: 0.0434
Epoch 40/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m327s←[0m 1s/step - accuracy: 0.9993 - loss: 0.0080 - val_accuracy: 0.9861 - val_loss: 0.0409
Epoch 41/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0079 - val_accuracy: 0.9878 - val_loss: 0.0419
Epoch 42/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0074 - val_accuracy: 0.9878 - val_loss: 0.0389
Epoch 43/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0070 - val_accuracy: 0.9856 - val_loss: 0.0396
Epoch 44/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9997 - loss: 0.0067 - val_accuracy: 0.9872 - val_loss: 0.0404
Epoch 45/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m294s←[0m 1s/step - accuracy: 0.9998 - loss: 0.0062 - val_accuracy: 0.9889 - val_loss: 0.0410
←[1m57/57←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m59s←[0m 1s/step - accuracy: 0.9872 - loss: 0.0438
New validation loss: 0.0389
New validation accuracy: 0.9878
Model saved to D:\03PersonalFiles\Thesis\I-Comprehend\src\models\resnet50v2_model.keras.
Model weights saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\weights\batch_6.weights.h5.
Training history saved to D:\03PersonalFiles\Thesis\I-Comprehend\experiments\logs\batch_6_history.csv.
Plot saved to D:\03PersonalFiles\Thesis\I-Comprehend\outputs\plots\ResNet50V2_plots\batch_6_training_history.png.

Loading data from D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\images\images_chunk_6.npy and D:\03PersonalFiles\Thesis\I-Comprehend\datasets\processed\labels\labels_chunk_6.npy (batch 7)...
Loaded image data with shape (9000, 256, 256, 3), and label data with shape (9000, 7).
Splitting training data and validation data
Split data into 7200 training and 1800 validation samples.
Training the model with batch 7...
Epoch 1/50
←[1m225/225←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m307s←[0m 1s/step - accuracy: 0.7091 - loss: 1.4643 - val_accuracy: 0.8411 - val_loss: 0.5283
Epoch 2/50
←[1m167/225←[0m ←[32m━━━━━━━━━━━━━━←[0m←[37m━━━━━━←[0m ←[1m1:08←[0m 1s/step - accuracy: 0.8552 - loss: 0.4658