{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import evaluate  # Bleu\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = T5TokenizerFast.from_pretrained(r\"D:\\02 Personal Files\\Thesis Related\\Main Thesis Project\\main\\thesis\\models\\qg_tokenizer\")\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(r\"D:\\02 Personal Files\\Thesis Related\\Main Thesis Project\\main\\thesis\\models\\qg_model\", return_dict=True)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
    "Q_LEN = 256   # Question Length\n",
    "T_LEN = 32    # Target Length\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\02 Personal Files\\Thesis Related\\Main Thesis Project\\main\\thesis\\datasets\\output.csv\")\n",
    "data = data.sample(n=10000).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QG_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answers']\n",
    "        self.question_type = self.data['question_type']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx] if isinstance(self.answer[idx], str) else self.answer[idx][0]\n",
    "        question_type = self.question_type[idx]\n",
    "        \n",
    "        context_with_type = f\"{question_type} {context}\"\n",
    "        \n",
    "        question_tokenized = self.tokenizer(\n",
    "            question, context_with_type, max_length=self.q_len, padding=\"max_length\",\n",
    "            truncation=True, add_special_tokens=True, return_tensors='pt'\n",
    "        )\n",
    "        answer_tokenized = self.tokenizer(\n",
    "            answer, max_length=self.t_len, padding=\"max_length\", \n",
    "            truncation=True, add_special_tokens=True, return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        labels = answer_tokenized[\"input_ids\"].squeeze()\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": question_tokenized[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": question_tokenized[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": answer_tokenized[\"attention_mask\"].squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QG_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 2000/2000 [3:00:28<00:00,  5.41s/it]  \n",
      "Validation batches: 100%|██████████| 500/500 [41:09<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 -> Train loss: 0.7560893682967872\tValidation loss: 0.3400475863069296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 2000/2000 [3:06:24<00:00,  5.59s/it]  \n",
      "Validation batches: 100%|██████████| 500/500 [41:03<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 -> Train loss: 0.586575129785575\tValidation loss: 0.2872920712665655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "    \n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "        \n",
    "    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL.save_pretrained(\"qg_model\")\n",
    "# TOKENIZER.save_pretrained(\"qg_tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
